{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esj1kzeQWNA_"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS2SAdLsWEHo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os\n",
        "from community import community_louvain\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhwFqDH3knIQ",
        "outputId": "c7bbb0a9-3737-46eb-9b3c-d546b4be9d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.11/dist-packages (0.16)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from python-louvain) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from python-louvain) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install python-louvain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pA1pf_zkwo7"
      },
      "outputs": [],
      "source": [
        "import community as community_louvain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teoe08FDYFBH"
      },
      "source": [
        "# Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ij3prZt0X-bj"
      },
      "outputs": [],
      "source": [
        "tweets = pd.read_excel(\"/content/tweets.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "UocJRPigY2nq",
        "outputId": "47954f13-4e5c-4fbe-a9ac-ac364129e192"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "tweets"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-5ab8513e-f1be-40cf-8d8e-87f991faaa6e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Vertex 1</th>\n",
              "      <th>Vertex 2</th>\n",
              "      <th>Colour</th>\n",
              "      <th>Width</th>\n",
              "      <th>Style</th>\n",
              "      <th>Opacity</th>\n",
              "      <th>Visibility</th>\n",
              "      <th>Label</th>\n",
              "      <th>Label Text Colour</th>\n",
              "      <th>Label Font Size</th>\n",
              "      <th>...</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>URLs in Tweet</th>\n",
              "      <th>Domains in Tweet</th>\n",
              "      <th>Hashtags in Tweet</th>\n",
              "      <th>Tweet Date (UTC)</th>\n",
              "      <th>Twitter Page for Tweet</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Imported ID</th>\n",
              "      <th>In-Reply Tweet ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sanchitabhartiy</td>\n",
              "      <td>thexoxoday</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>RT @thexoxoday: Our #Contest is #live! #RT and...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>contest live rt</td>\n",
              "      <td>2017-01-25 11:27:34</td>\n",
              "      <td>https://twitter.com/#!/sanchitabhartiy/status/...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>824217142681862144</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ratneshnagori</td>\n",
              "      <td>divyamisra2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>@thexoxoday @kunalgupta09 @ekta_k88 @kp_85 @sn...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2017-01-25 11:31:10</td>\n",
              "      <td>https://twitter.com/#!/ratneshnagori/status/82...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>824218047707652096</td>\n",
              "      <td>8.242167e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ratneshnagori</td>\n",
              "      <td>kp_85</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>@thexoxoday @kunalgupta09 @ekta_k88 @kp_85 @sn...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2017-01-25 11:31:10</td>\n",
              "      <td>https://twitter.com/#!/ratneshnagori/status/82...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>824218047707652096</td>\n",
              "      <td>8.242167e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ratneshnagori</td>\n",
              "      <td>soodabhinav08</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>@thexoxoday @kunalgupta09 @ekta_k88 @kp_85 @sn...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2017-01-25 11:31:10</td>\n",
              "      <td>https://twitter.com/#!/ratneshnagori/status/82...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>824218047707652096</td>\n",
              "      <td>8.242167e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ratneshnagori</td>\n",
              "      <td>snehalataj</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>@thexoxoday @kunalgupta09 @ekta_k88 @kp_85 @sn...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2017-01-25 11:31:10</td>\n",
              "      <td>https://twitter.com/#!/ratneshnagori/status/82...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>824218047707652096</td>\n",
              "      <td>8.242167e+17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 26 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ab8513e-f1be-40cf-8d8e-87f991faaa6e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5ab8513e-f1be-40cf-8d8e-87f991faaa6e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5ab8513e-f1be-40cf-8d8e-87f991faaa6e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-62ab9a35-cd7f-4fbe-ba0e-ecd3e6fbfb2a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-62ab9a35-cd7f-4fbe-ba0e-ecd3e6fbfb2a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-62ab9a35-cd7f-4fbe-ba0e-ecd3e6fbfb2a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          Vertex 1       Vertex 2  Colour  Width  Style  Opacity  Visibility  \\\n",
              "0  sanchitabhartiy     thexoxoday     NaN    NaN    NaN      NaN         NaN   \n",
              "1    ratneshnagori    divyamisra2     NaN    NaN    NaN      NaN         NaN   \n",
              "2    ratneshnagori          kp_85     NaN    NaN    NaN      NaN         NaN   \n",
              "3    ratneshnagori  soodabhinav08     NaN    NaN    NaN      NaN         NaN   \n",
              "4    ratneshnagori     snehalataj     NaN    NaN    NaN      NaN         NaN   \n",
              "\n",
              "   Label  Label Text Colour  Label Font Size  ...  \\\n",
              "0    NaN                NaN              NaN  ...   \n",
              "1    NaN                NaN              NaN  ...   \n",
              "2    NaN                NaN              NaN  ...   \n",
              "3    NaN                NaN              NaN  ...   \n",
              "4    NaN                NaN              NaN  ...   \n",
              "\n",
              "                                               Tweet  URLs in Tweet  \\\n",
              "0  RT @thexoxoday: Our #Contest is #live! #RT and...            NaN   \n",
              "1  @thexoxoday @kunalgupta09 @ekta_k88 @kp_85 @sn...            NaN   \n",
              "2  @thexoxoday @kunalgupta09 @ekta_k88 @kp_85 @sn...            NaN   \n",
              "3  @thexoxoday @kunalgupta09 @ekta_k88 @kp_85 @sn...            NaN   \n",
              "4  @thexoxoday @kunalgupta09 @ekta_k88 @kp_85 @sn...            NaN   \n",
              "\n",
              "   Domains in Tweet  Hashtags in Tweet    Tweet Date (UTC)  \\\n",
              "0               NaN    contest live rt 2017-01-25 11:27:34   \n",
              "1               NaN                NaN 2017-01-25 11:31:10   \n",
              "2               NaN                NaN 2017-01-25 11:31:10   \n",
              "3               NaN                NaN 2017-01-25 11:31:10   \n",
              "4               NaN                NaN 2017-01-25 11:31:10   \n",
              "\n",
              "                              Twitter Page for Tweet Latitude Longitude  \\\n",
              "0  https://twitter.com/#!/sanchitabhartiy/status/...      NaN       NaN   \n",
              "1  https://twitter.com/#!/ratneshnagori/status/82...      NaN       NaN   \n",
              "2  https://twitter.com/#!/ratneshnagori/status/82...      NaN       NaN   \n",
              "3  https://twitter.com/#!/ratneshnagori/status/82...      NaN       NaN   \n",
              "4  https://twitter.com/#!/ratneshnagori/status/82...      NaN       NaN   \n",
              "\n",
              "          Imported ID In-Reply Tweet ID  \n",
              "0  824217142681862144               NaN  \n",
              "1  824218047707652096      8.242167e+17  \n",
              "2  824218047707652096      8.242167e+17  \n",
              "3  824218047707652096      8.242167e+17  \n",
              "4  824218047707652096      8.242167e+17  \n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QBtn252YYJe"
      },
      "source": [
        "# Creating a Directed graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehQH97BHYYeD"
      },
      "outputs": [],
      "source": [
        "G = nx.DiGraph()\n",
        "G_mentions = nx.DiGraph()\n",
        "G_replies = nx.DiGraph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJtYv50OYscp"
      },
      "source": [
        "## Adding all edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph9thdmBYsi2",
        "outputId": "1f101aad-c8b4-4c36-b55e-f6b1620e6073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined graph: 2493 nodes, 3204 edges\n",
            "Mentions graph: 2489 nodes, 3184 edges\n",
            "Replies graph: 91 nodes, 94 edges\n"
          ]
        }
      ],
      "source": [
        "for _, row in tweets.iterrows():\n",
        "    if pd.notna(row['Vertex 1']) and pd.notna(row['Vertex 2']):\n",
        "        relation = row['Relationship']\n",
        "\n",
        "        if relation in ['Mentions', 'Replies to']:\n",
        "            G.add_edge(row['Vertex 1'], row['Vertex 2'])  # Main graph\n",
        "\n",
        "            if relation == 'Mentions':\n",
        "                G_mentions.add_edge(row['Vertex 1'], row['Vertex 2'])\n",
        "            elif relation == 'Replies to':\n",
        "                G_replies.add_edge(row['Vertex 1'], row['Vertex 2'])\n",
        "\n",
        "print(f\"Combined graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
        "print(f\"Mentions graph: {G_mentions.number_of_nodes()} nodes, {G_mentions.number_of_edges()} edges\")\n",
        "print(f\"Replies graph: {G_replies.number_of_nodes()} nodes, {G_replies.number_of_edges()} edges\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iaZCUk2ZBIk"
      },
      "source": [
        "Removing the tweets only keeping teh mentions and repies - because for the tweets it will give unnecessary importance to thexoxoday as both vertex 1 and vertetx 2 will by thexoxoday its nit as if though theres any interaction\n",
        "\n",
        "There are not many more edges than there are nodes - that means not too many connections - avg degree - 1.29 - relatively sparse network especially when considering that its a social media network where ideally it should be dense for a company that has engagement\n",
        "\n",
        "very few replies made to xoxoday tweets more mentions for contests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO3gdGnDZpsx"
      },
      "source": [
        "# Calculating all Centrality Measures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57nP77ZubV04"
      },
      "source": [
        "## Wrapper Function to Safely Compute Centrality Measures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mW6sD9dSZx1z"
      },
      "outputs": [],
      "source": [
        "def safe_centrality(func, graph, **kwargs):\n",
        "    try:\n",
        "        return func(graph, **kwargs)\n",
        "    except Exception as e:\n",
        "        print(f\"Error computing {func.__name__}: {e}\")\n",
        "        return {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUttxflBbiB8"
      },
      "source": [
        "## Basic Centrality Measures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbzbuYu6biN5",
        "outputId": "a455853b-a1d4-46b2-f70d-1765718cb754"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Calculating centralities for Combined...\n",
            "  - In/Out Degree Centrality\n",
            "  - Betweenness Centrality\n",
            "  - Closeness Centrality (on largest WCC)\n",
            "  - Eigenvector Centrality\n",
            "  - PageRank\n",
            "  - HITS\n",
            "  - Katz Centrality\n",
            "\n",
            "Calculating centralities for Mentions...\n",
            "  - In/Out Degree Centrality\n",
            "  - Betweenness Centrality\n",
            "  - Closeness Centrality (on largest WCC)\n",
            "  - Eigenvector Centrality\n",
            "  - PageRank\n",
            "  - HITS\n",
            "  - Katz Centrality\n",
            "\n",
            "Calculating centralities for Replies...\n",
            "  - In/Out Degree Centrality\n",
            "  - Betweenness Centrality\n",
            "  - Closeness Centrality (on largest WCC)\n",
            "  - Eigenvector Centrality\n",
            "  - PageRank\n",
            "  - HITS\n",
            "  - Katz Centrality\n"
          ]
        }
      ],
      "source": [
        "def compute_centralities(graph, name=\"Graph\"):\n",
        "    print(f\"\\nCalculating centralities for {name}...\")\n",
        "\n",
        "    print(\"  - In/Out Degree Centrality\")\n",
        "    in_degree = nx.in_degree_centrality(graph)\n",
        "    out_degree = nx.out_degree_centrality(graph)\n",
        "\n",
        "    print(\"  - Betweenness Centrality\")\n",
        "    betweenness = safe_centrality(nx.betweenness_centrality, graph)\n",
        "\n",
        "    print(\"  - Closeness Centrality (on largest WCC)\")\n",
        "    if nx.is_weakly_connected(graph):\n",
        "        closeness = safe_centrality(nx.closeness_centrality, graph)\n",
        "    else:\n",
        "        largest_wcc = max(nx.weakly_connected_components(graph), key=len)\n",
        "        subgraph = graph.subgraph(largest_wcc)\n",
        "        closeness = safe_centrality(nx.closeness_centrality, subgraph)\n",
        "\n",
        "    print(\"  - Eigenvector Centrality\")\n",
        "    eigenvector = safe_centrality(nx.eigenvector_centrality, graph)\n",
        "\n",
        "    print(\"  - PageRank\")\n",
        "    pagerank = safe_centrality(nx.pagerank, graph)\n",
        "\n",
        "    print(\"  - HITS\")\n",
        "    hubs, authorities = safe_centrality(nx.hits, graph)\n",
        "\n",
        "    print(\"  - Katz Centrality\")\n",
        "    katz = safe_centrality(nx.katz_centrality_numpy, graph)\n",
        "\n",
        "    return {\n",
        "        'in_degree': in_degree,\n",
        "        'out_degree': out_degree,\n",
        "        'betweenness': betweenness,\n",
        "        'closeness': closeness,\n",
        "        'eigenvector': eigenvector,\n",
        "        'pagerank': pagerank,\n",
        "        'hubs': hubs,\n",
        "        'authorities': authorities,\n",
        "        'katz': katz\n",
        "    }\n",
        "\n",
        "# Run for all three graphs\n",
        "centralities_all = compute_centralities(G, \"Combined\")\n",
        "centralities_mentions = compute_centralities(G_mentions, \"Mentions\")\n",
        "centralities_replies = compute_centralities(G_replies, \"Replies\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBKjHWJlc16m"
      },
      "source": [
        "## Combine All Measures into a Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lAQlkUAKc2IX"
      },
      "outputs": [],
      "source": [
        "def build_centrality_df(graph, centralities):\n",
        "    nodes = list(graph.nodes())\n",
        "    return pd.DataFrame({\n",
        "        'node': nodes,\n",
        "        'in_degree': [centralities['in_degree'].get(node, 0) for node in nodes],\n",
        "        'out_degree': [centralities['out_degree'].get(node, 0) for node in nodes],\n",
        "        'betweenness': [centralities['betweenness'].get(node, 0) for node in nodes],\n",
        "        'closeness': [centralities['closeness'].get(node, 0) for node in nodes],\n",
        "        'eigenvector': [centralities['eigenvector'].get(node, 0) for node in nodes],\n",
        "        'pagerank': [centralities['pagerank'].get(node, 0) for node in nodes],\n",
        "        'hub_score': [centralities['hubs'].get(node, 0) for node in nodes],\n",
        "        'authority_score': [centralities['authorities'].get(node, 0) for node in nodes],\n",
        "        'katz': [centralities['katz'].get(node, 0) for node in nodes]\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_AGUog4AoDDe"
      },
      "outputs": [],
      "source": [
        "df_all = build_centrality_df(G, centralities_all)\n",
        "df_mentions = build_centrality_df(G_mentions, centralities_mentions)\n",
        "df_replies = build_centrality_df(G_replies, centralities_replies)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylHN2mNKeXH6"
      },
      "source": [
        "# Identify Top Users By Each Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VHo_UefneXaC"
      },
      "outputs": [],
      "source": [
        "def print_top_nodes(df, label=\"Graph\"):\n",
        "    def get_top_nodes(df, measure, n=10):\n",
        "        return df.sort_values(by=measure, ascending=False).head(n)\n",
        "\n",
        "    print(f\"\\nTop 10 Nodes for {label}:\\n\" + \"-\" * 40)\n",
        "\n",
        "    print(\"\\nIn-Degree:\")\n",
        "    print(get_top_nodes(df, 'in_degree')[['node', 'in_degree']])\n",
        "\n",
        "    print(\"\\nOut-Degree:\")\n",
        "    print(get_top_nodes(df, 'out_degree')[['node', 'out_degree']])\n",
        "\n",
        "    print(\"\\nBetweenness Centrality:\")\n",
        "    print(get_top_nodes(df, 'betweenness')[['node', 'betweenness']])\n",
        "\n",
        "    print(\"\\nCloseness Centrality:\")\n",
        "    print(get_top_nodes(df, 'closeness')[['node', 'closeness']])\n",
        "\n",
        "    print(\"\\nEigenvector Centrality:\")\n",
        "    print(get_top_nodes(df, 'eigenvector')[['node', 'eigenvector']])\n",
        "\n",
        "    print(\"\\nPageRank:\")\n",
        "    print(get_top_nodes(df, 'pagerank')[['node', 'pagerank']])\n",
        "\n",
        "    print(\"\\nHubs Score:\")\n",
        "    print(get_top_nodes(df, 'hub_score')[['node', 'hub_score']])\n",
        "\n",
        "    print(\"\\nAuthorities Score:\")\n",
        "    print(get_top_nodes(df, 'authority_score')[['node', 'authority_score']])\n",
        "\n",
        "    print(\"\\nKatz Centrality:\")\n",
        "    print(get_top_nodes(df, 'katz')[['node', 'katz']])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y8qXppcHole2",
        "outputId": "09a5bf80-232c-49fb-b1e2-e3324c942a8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 10 Nodes for Combined Graph:\n",
            "----------------------------------------\n",
            "\n",
            "In-Degree:\n",
            "                node  in_degree\n",
            "1         thexoxoday   0.099518\n",
            "23          dewcool2   0.015249\n",
            "54     iheartcontest   0.006019\n",
            "108    pinkydholakia   0.005618\n",
            "44     contestmantra   0.005618\n",
            "55      contesttable   0.005618\n",
            "52             broke   0.005217\n",
            "53    photo_contests   0.005217\n",
            "62   contestadventur   0.004815\n",
            "101   india4contests   0.004815\n",
            "\n",
            "Out-Degree:\n",
            "                 node  out_degree\n",
            "62    contestadventur    0.777689\n",
            "2261           shwtz7    0.026485\n",
            "1          thexoxoday    0.020064\n",
            "240       girija_kriz    0.014446\n",
            "2187        nehalroys    0.010835\n",
            "307          kumar623    0.010433\n",
            "2249    shraddha_bari    0.010032\n",
            "251      blessedkamal    0.010032\n",
            "270   karrivinodkumar    0.009631\n",
            "2248  pratima_talreja    0.007624\n",
            "\n",
            "Betweenness Centrality:\n",
            "                 node  betweenness\n",
            "62    contestadventur     0.080841\n",
            "1          thexoxoday     0.079779\n",
            "2248  pratima_talreja     0.001631\n",
            "2249    shraddha_bari     0.001322\n",
            "2244    priyabansal66     0.001022\n",
            "2173   abhineshkgupta     0.000910\n",
            "251      blessedkamal     0.000752\n",
            "2314    mehandisuresh     0.000674\n",
            "157     binny_kukreja     0.000567\n",
            "128      mgossipqueen     0.000554\n",
            "\n",
            "Closeness Centrality:\n",
            "                node  closeness\n",
            "1         thexoxoday   0.099518\n",
            "54     iheartcontest   0.051511\n",
            "55      contesttable   0.051405\n",
            "44     contestmantra   0.051205\n",
            "100      contestmela   0.051088\n",
            "62   contestadventur   0.050993\n",
            "101   india4contests   0.050993\n",
            "144    plum_paradise   0.050984\n",
            "143    mala_24amrish   0.050984\n",
            "142    ruchirasalvi2   0.050984\n",
            "\n",
            "Eigenvector Centrality:\n",
            "                node  eigenvector\n",
            "1         thexoxoday     0.383669\n",
            "54     iheartcontest     0.109951\n",
            "581      thefreejinn     0.101677\n",
            "44     contestmantra     0.100633\n",
            "101   india4contests     0.100633\n",
            "100      contestmela     0.100633\n",
            "227     vineetsonkar     0.100211\n",
            "577   contests2share     0.096958\n",
            "2463      uber_india     0.096565\n",
            "157    binny_kukreja     0.095122\n",
            "\n",
            "PageRank:\n",
            "                 node  pagerank\n",
            "1          thexoxoday  0.052631\n",
            "23           dewcool2  0.003231\n",
            "2463       uber_india  0.001879\n",
            "44      contestmantra  0.001753\n",
            "2475   prreleasewatch  0.001744\n",
            "582     contestindia_  0.001742\n",
            "54      iheartcontest  0.001654\n",
            "55       contesttable  0.001653\n",
            "62    contestadventur  0.001626\n",
            "2491             uber  0.001585\n",
            "\n",
            "Hubs Score:\n",
            "                 node  hub_score\n",
            "62    contestadventur   0.754418\n",
            "240       girija_kriz   0.006202\n",
            "270   karrivinodkumar   0.005098\n",
            "251      blessedkamal   0.005026\n",
            "2249    shraddha_bari   0.005015\n",
            "2187        nehalroys   0.004723\n",
            "1          thexoxoday   0.004218\n",
            "2314    mehandisuresh   0.003784\n",
            "307          kumar623   0.003357\n",
            "166   bharatmaheshw16   0.003306\n",
            "\n",
            "Authorities Score:\n",
            "               node  authority_score\n",
            "1        thexoxoday         0.000680\n",
            "23         dewcool2         0.000560\n",
            "44    contestmantra         0.000543\n",
            "101  india4contests         0.000541\n",
            "100     contestmela         0.000540\n",
            "54    iheartcontest         0.000537\n",
            "108   pinkydholakia         0.000537\n",
            "581     thefreejinn         0.000536\n",
            "6        snehalataj         0.000535\n",
            "126         babubeg         0.000532\n",
            "\n",
            "Katz Centrality:\n",
            "                node      katz\n",
            "1         thexoxoday  0.398202\n",
            "23          dewcool2  0.081937\n",
            "54     iheartcontest  0.078744\n",
            "44     contestmantra  0.074915\n",
            "101   india4contests  0.072578\n",
            "55      contesttable  0.072023\n",
            "100      contestmela  0.071532\n",
            "581      thefreejinn  0.069175\n",
            "62   contestadventur  0.067211\n",
            "577   contests2share  0.066898\n",
            "\n",
            "Top 10 Nodes for Mentions Graph:\n",
            "----------------------------------------\n",
            "\n",
            "In-Degree:\n",
            "                node  in_degree\n",
            "1         thexoxoday   0.096865\n",
            "23          dewcool2   0.015273\n",
            "54     iheartcontest   0.006029\n",
            "44     contestmantra   0.005627\n",
            "108    pinkydholakia   0.005627\n",
            "55      contesttable   0.005627\n",
            "53    photo_contests   0.005225\n",
            "52             broke   0.005225\n",
            "62   contestadventur   0.004823\n",
            "101   india4contests   0.004823\n",
            "\n",
            "Out-Degree:\n",
            "                 node  out_degree\n",
            "62    contestadventur    0.778939\n",
            "2260           shwtz7    0.026527\n",
            "1          thexoxoday    0.016881\n",
            "239       girija_kriz    0.014469\n",
            "2186        nehalroys    0.010852\n",
            "306          kumar623    0.010450\n",
            "2248    shraddha_bari    0.010048\n",
            "250      blessedkamal    0.010048\n",
            "269   karrivinodkumar    0.009646\n",
            "2247  pratima_talreja    0.007637\n",
            "\n",
            "Betweenness Centrality:\n",
            "                 node  betweenness\n",
            "62    contestadventur     0.081155\n",
            "1          thexoxoday     0.078675\n",
            "2247  pratima_talreja     0.001616\n",
            "2248    shraddha_bari     0.001321\n",
            "2243    priyabansal66     0.001014\n",
            "250      blessedkamal     0.000964\n",
            "2172   abhineshkgupta     0.000903\n",
            "2313    mehandisuresh     0.000684\n",
            "128      mgossipqueen     0.000549\n",
            "2198      sidbansal22     0.000531\n",
            "\n",
            "Closeness Centrality:\n",
            "                node  closeness\n",
            "1         thexoxoday   0.096891\n",
            "54     iheartcontest   0.050673\n",
            "44     contestmantra   0.050578\n",
            "55      contesttable   0.050463\n",
            "100      contestmela   0.050463\n",
            "101   india4contests   0.050367\n",
            "62   contestadventur   0.050262\n",
            "144    plum_paradise   0.050048\n",
            "143    mala_24amrish   0.050048\n",
            "142    ruchirasalvi2   0.050048\n",
            "\n",
            "Eigenvector Centrality:\n",
            "                node  eigenvector\n",
            "1         thexoxoday     0.351894\n",
            "54     iheartcontest     0.111814\n",
            "580      thefreejinn     0.104738\n",
            "44     contestmantra     0.103723\n",
            "101   india4contests     0.103723\n",
            "100      contestmela     0.103723\n",
            "579  contestkiduniya     0.096319\n",
            "55      contesttable     0.094817\n",
            "23          dewcool2     0.092102\n",
            "62   contestadventur     0.089775\n",
            "\n",
            "PageRank:\n",
            "                 node  pagerank\n",
            "1          thexoxoday  0.051372\n",
            "23           dewcool2  0.003203\n",
            "2487             uber  0.001969\n",
            "2471   prreleasewatch  0.001927\n",
            "44      contestmantra  0.001918\n",
            "581     contestindia_  0.001892\n",
            "54      iheartcontest  0.001808\n",
            "55       contesttable  0.001807\n",
            "62    contestadventur  0.001782\n",
            "2418          olacabs  0.001748\n",
            "\n",
            "Hubs Score:\n",
            "                 node  hub_score\n",
            "62    contestadventur   0.760104\n",
            "239       girija_kriz   0.006238\n",
            "269   karrivinodkumar   0.005114\n",
            "250      blessedkamal   0.005053\n",
            "2248    shraddha_bari   0.005038\n",
            "2186        nehalroys   0.004740\n",
            "2313    mehandisuresh   0.003801\n",
            "306          kumar623   0.003377\n",
            "166   bharatmaheshw16   0.003326\n",
            "2260           shwtz7   0.003175\n",
            "\n",
            "Authorities Score:\n",
            "               node  authority_score\n",
            "1        thexoxoday         0.000673\n",
            "23         dewcool2         0.000560\n",
            "44    contestmantra         0.000541\n",
            "101  india4contests         0.000540\n",
            "100     contestmela         0.000539\n",
            "108   pinkydholakia         0.000537\n",
            "54    iheartcontest         0.000536\n",
            "580     thefreejinn         0.000535\n",
            "6        snehalataj         0.000535\n",
            "126         babubeg         0.000532\n",
            "\n",
            "Katz Centrality:\n",
            "                node      katz\n",
            "1         thexoxoday  0.383601\n",
            "23          dewcool2  0.080305\n",
            "54     iheartcontest  0.078276\n",
            "44     contestmantra  0.074744\n",
            "101   india4contests  0.072285\n",
            "55      contesttable  0.071577\n",
            "100      contestmela  0.071185\n",
            "580      thefreejinn  0.068692\n",
            "62   contestadventur  0.066989\n",
            "579  contestkiduniya  0.063457\n",
            "\n",
            "Top 10 Nodes for Replies Graph:\n",
            "----------------------------------------\n",
            "\n",
            "In-Degree:\n",
            "              node  in_degree\n",
            "1       thexoxoday   0.855556\n",
            "89      uber_india   0.022222\n",
            "21    mgossipqueen   0.011111\n",
            "43   binny_kukreja   0.011111\n",
            "60  deepakberiwala   0.011111\n",
            "85  contests2share   0.011111\n",
            "56          shwtz7   0.011111\n",
            "46      nehayagnik   0.011111\n",
            "45    kajol_saxena   0.011111\n",
            "33     epicangel40   0.011111\n",
            "\n",
            "Out-Degree:\n",
            "               node  out_degree\n",
            "1        thexoxoday    0.088889\n",
            "63     sureshnakoda    0.022222\n",
            "46       nehayagnik    0.022222\n",
            "3   nehagup42992144    0.011111\n",
            "4      ajayageecha1    0.011111\n",
            "5          jainnamu    0.011111\n",
            "6        romeromash    0.011111\n",
            "7   shikhabhansali9    0.011111\n",
            "8    jayeshmehta377    0.011111\n",
            "0     ratneshnagori    0.011111\n",
            "\n",
            "Betweenness Centrality:\n",
            "               node  betweenness\n",
            "1        thexoxoday     0.080400\n",
            "21     mgossipqueen     0.001124\n",
            "33      epicangel40     0.001124\n",
            "46       nehayagnik     0.001124\n",
            "56           shwtz7     0.001124\n",
            "3   nehagup42992144     0.000000\n",
            "6        romeromash     0.000000\n",
            "7   shikhabhansali9     0.000000\n",
            "4      ajayageecha1     0.000000\n",
            "5          jainnamu     0.000000\n",
            "\n",
            "Closeness Centrality:\n",
            "              node  closeness\n",
            "1       thexoxoday   0.908097\n",
            "86   contestweeter   0.473688\n",
            "82       bpbmumbai   0.473688\n",
            "84  contestimeline   0.473688\n",
            "85  contests2share   0.473688\n",
            "75    vineetsonkar   0.467807\n",
            "43   binny_kukreja   0.467807\n",
            "60  deepakberiwala   0.467807\n",
            "83          reyen7   0.467807\n",
            "21    mgossipqueen   0.011765\n",
            "\n",
            "Eigenvector Centrality:\n",
            "              node  eigenvector\n",
            "1       thexoxoday     0.577365\n",
            "82       bpbmumbai     0.288672\n",
            "43   binny_kukreja     0.288672\n",
            "60  deepakberiwala     0.288672\n",
            "84  contestimeline     0.288672\n",
            "85  contests2share     0.288672\n",
            "86   contestweeter     0.288672\n",
            "83          reyen7     0.288672\n",
            "75    vineetsonkar     0.288672\n",
            "45    kajol_saxena     0.000064\n",
            "\n",
            "PageRank:\n",
            "              node  pagerank\n",
            "1       thexoxoday  0.361784\n",
            "82       bpbmumbai  0.041792\n",
            "43   binny_kukreja  0.041792\n",
            "60  deepakberiwala  0.041792\n",
            "84  contestimeline  0.041792\n",
            "85  contests2share  0.041792\n",
            "86   contestweeter  0.041792\n",
            "83          reyen7  0.041792\n",
            "75    vineetsonkar  0.041792\n",
            "46      nehayagnik  0.009709\n",
            "\n",
            "Hubs Score:\n",
            "               node  hub_score\n",
            "46       nehayagnik   0.013153\n",
            "63     sureshnakoda   0.013153\n",
            "0     ratneshnagori   0.012983\n",
            "7   shikhabhansali9   0.012983\n",
            "4      ajayageecha1   0.012983\n",
            "5          jainnamu   0.012983\n",
            "6        romeromash   0.012983\n",
            "9          smadan4u   0.012983\n",
            "8    jayeshmehta377   0.012983\n",
            "2    ankitajain0911   0.012983\n",
            "\n",
            "Authorities Score:\n",
            "              node  authority_score\n",
            "1       thexoxoday     9.743676e-01\n",
            "45    kajol_saxena     1.281619e-02\n",
            "62   mehandisuresh     1.281619e-02\n",
            "29     shubh_softy     3.538343e-17\n",
            "23  danceeatrepeat     3.026229e-17\n",
            "53       rehanak55     2.835211e-17\n",
            "21    mgossipqueen     2.621833e-17\n",
            "73       fotokiran     2.567884e-17\n",
            "33     epicangel40     1.737027e-17\n",
            "16       srirajee1     1.452296e-17\n",
            "\n",
            "Katz Centrality:\n",
            "              node      katz\n",
            "1       thexoxoday  0.650645\n",
            "60  deepakberiwala  0.136441\n",
            "43   binny_kukreja  0.136441\n",
            "86   contestweeter  0.136441\n",
            "85  contests2share  0.136441\n",
            "84  contestimeline  0.136441\n",
            "82       bpbmumbai  0.136441\n",
            "83          reyen7  0.136441\n",
            "75    vineetsonkar  0.136441\n",
            "89      uber_india  0.085651\n"
          ]
        }
      ],
      "source": [
        "print_top_nodes(df_all, \"Combined Graph\")\n",
        "print_top_nodes(df_mentions, \"Mentions Graph\")\n",
        "print_top_nodes(df_replies, \"Replies Graph\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXLGIRcgfiYB"
      },
      "source": [
        "Most influential accounts are the contest accounts probaly not reperesenting actual users or buyers but simply accounts that probably look and retweet contest tweets from different companies like the giveaway companies specifically looking and retweeting maybe to their followers - this gives the impressions to even new users that this company just tries to give contests because they arent doing well - like you shouldnt be that desperate of a company\n",
        "\n",
        "in the top for replies to nodes there are less contest users and actual maybe general users and followers and acounts and buyers\n",
        "\n",
        "\n",
        "users\n",
        "dewcool2 - indegree, outdegree, betweenness, katz, authorities, eigenvector, pagerank,\n",
        "shraddha_bari - outdegree, hubs\n",
        "pratima_talreja - betweenness\n",
        "girija_kriz\n",
        "thefreejinn - eigenvector, katz, authorities\n",
        "blessed_kamal\n",
        "\n",
        "\n",
        "replies\n",
        "nehayagnik - indegree,outdegree,betweenness, pagerank, hubs\n",
        "mgossipqueen - indegree, betweenness, closeness\n",
        "binee_kukreja - closeness, indegree, eigenvector, katz\n",
        "bpb_mumbai - eigenvector, closeness, katz\n",
        "deepakberiwala -eigenvector, pagerank, closeness, indegree, katz\n",
        "\n",
        "lots of contests\n",
        "iheartcontest\n",
        "contesttable\n",
        "contestmantra\n",
        "contestmela\n",
        "contests2share\n",
        "contestadventur\n",
        "contestindia\n",
        "photocontests\n",
        "contestkiduniya\n",
        "\n",
        "interesting - users - mentioms\n",
        "uber - pagerank\n",
        "olacabs - pagerank\n",
        "\n",
        "interesting - users - replies\n",
        "uber - pagerank\n",
        "uber_india - indegeree, katz\n",
        "olacabs - pagerank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epG36hrp-QJs"
      },
      "source": [
        "# Connected Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GflNArR1fhvi",
        "outputId": "677e35bf-0970-4f2b-bafb-de35ab6e5b2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Full Graph (Mentions + Replies) - Connected Components:\n",
            "  Weakly connected components: 1\n",
            "    Largest size: 2493\n",
            "    Smallest size: 2493\n",
            "    Average size: 2493.00\n",
            "  Strongly connected components: 2406\n",
            "    Largest size: 73\n",
            "    Smallest size: 1\n",
            "    Average size: 1.04\n",
            "\n",
            "Mentions Graph - Connected Components:\n",
            "  Weakly connected components: 1\n",
            "    Largest size: 2489\n",
            "    Smallest size: 2489\n",
            "    Average size: 2489.00\n",
            "  Strongly connected components: 2406\n",
            "    Largest size: 70\n",
            "    Smallest size: 1\n",
            "    Average size: 1.03\n",
            "\n",
            "Replies Graph - Connected Components:\n",
            "  Weakly connected components: 3\n",
            "    Largest size: 86\n",
            "    Smallest size: 2\n",
            "    Average size: 30.33\n",
            "  Strongly connected components: 86\n",
            "    Largest size: 5\n",
            "    Smallest size: 1\n",
            "    Average size: 1.06\n"
          ]
        }
      ],
      "source": [
        "def print_connected_components_info(graph, name):\n",
        "    weakly_connected = list(nx.weakly_connected_components(graph))\n",
        "    strongly_connected = list(nx.strongly_connected_components(graph))\n",
        "\n",
        "    wcc_sizes = [len(comp) for comp in weakly_connected]\n",
        "    scc_sizes = [len(comp) for comp in strongly_connected]\n",
        "\n",
        "    print(f\"\\n{name} - Connected Components:\")\n",
        "\n",
        "    print(f\"  Weakly connected components: {len(weakly_connected)}\")\n",
        "    print(f\"    Largest size: {max(wcc_sizes)}\")\n",
        "    print(f\"    Smallest size: {min(wcc_sizes)}\")\n",
        "    print(f\"    Average size: {sum(wcc_sizes) / len(wcc_sizes):.2f}\")\n",
        "\n",
        "    print(f\"  Strongly connected components: {len(strongly_connected)}\")\n",
        "    print(f\"    Largest size: {max(scc_sizes)}\")\n",
        "    print(f\"    Smallest size: {min(scc_sizes)}\")\n",
        "    print(f\"    Average size: {sum(scc_sizes) / len(scc_sizes):.2f}\")\n",
        "\n",
        "# Run for all graphs\n",
        "print_connected_components_info(G, \"Full Graph (Mentions + Replies)\")\n",
        "print_connected_components_info(G_mentions, \"Mentions Graph\")\n",
        "print_connected_components_info(G_replies, \"Replies Graph\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cySAXzF8J9ef",
        "outputId": "09cf74d7-1311-4972-c1bb-58caab903b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Full Graph (Mentions + Replies) without xoxoday - Connected Components:\n",
            "  Weakly connected components: 132\n",
            "    Largest size: 2314\n",
            "    Smallest size: 1\n",
            "    Average size: 18.88\n",
            "  Strongly connected components: 2434\n",
            "    Largest size: 38\n",
            "    Smallest size: 1\n",
            "    Average size: 1.02\n",
            "\n",
            "Mentions Graph without xoxoday - Connected Components:\n",
            "  Weakly connected components: 131\n",
            "    Largest size: 2311\n",
            "    Smallest size: 1\n",
            "    Average size: 18.99\n",
            "  Strongly connected components: 2432\n",
            "    Largest size: 38\n",
            "    Smallest size: 1\n",
            "    Average size: 1.02\n",
            "\n",
            "Replies Graph without xoxoday - Connected Components:\n",
            "  Weakly connected components: 82\n",
            "    Largest size: 3\n",
            "    Smallest size: 1\n",
            "    Average size: 1.10\n",
            "  Strongly connected components: 89\n",
            "    Largest size: 2\n",
            "    Smallest size: 1\n",
            "    Average size: 1.01\n"
          ]
        }
      ],
      "source": [
        "# Remove 'xoxoday' node from the graph\n",
        "G_no_xoxoday = G.copy()\n",
        "G_no_xoxoday.remove_node('thexoxoday')\n",
        "\n",
        "# Make copies of the Mentions and Replies graphs and remove 'xoxoday' from them\n",
        "G_mentions_no_xoxoday = G_mentions.copy()\n",
        "G_mentions_no_xoxoday.remove_node('thexoxoday')\n",
        "\n",
        "G_replies_no_xoxoday = G_replies.copy()\n",
        "G_replies_no_xoxoday.remove_node('thexoxoday')\n",
        "\n",
        "# Recompute connected components for the graph without 'xoxoday'\n",
        "print_connected_components_info(G_no_xoxoday, \"Full Graph (Mentions + Replies) without xoxoday\")\n",
        "print_connected_components_info(G_mentions_no_xoxoday, \"Mentions Graph without xoxoday\")\n",
        "print_connected_components_info(G_replies_no_xoxoday, \"Replies Graph without xoxoday\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su3jAhAEMIwq"
      },
      "source": [
        "# Transivity / Clustering Coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pijiOUqUMI2v",
        "outputId": "b62e4f9f-33ff-4897-e1f7-db14ad07d795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average clustering coefficient for Full Graph (Directed): 0.045483681173639566\n",
            "\n",
            "Average clustering coefficient for Mentions Graph (Directed): 0.044164230486861536\n",
            "\n",
            "Average clustering coefficient for Replies Graph (Directed): 0.01099055179257086\n"
          ]
        }
      ],
      "source": [
        "# Transitivity/Clustering coefficient\n",
        "# Calculate average clustering coefficient for the Full Graph (Mentions + Replies)\n",
        "avg_clustering_full = nx.average_clustering(G)\n",
        "print(f\"\\nAverage clustering coefficient for Full Graph (Directed): {avg_clustering_full}\")\n",
        "\n",
        "# Calculate average clustering coefficient for the Mentions Graph\n",
        "avg_clustering_mentions = nx.average_clustering(G_mentions)\n",
        "print(f\"\\nAverage clustering coefficient for Mentions Graph (Directed): {avg_clustering_mentions}\")\n",
        "\n",
        "# Calculate average clustering coefficient for the Replies Graph\n",
        "avg_clustering_replies = nx.average_clustering(G_replies)\n",
        "print(f\"\\nAverage clustering coefficient for Replies Graph (Directed): {avg_clustering_replies}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H7ION8uKMw-P",
        "outputId": "148eab96-9f8a-4796-ed1e-b2f72a7efcad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average clustering coefficient for Full Graph without 'xoxoday' (Directed): 0.03682600606137311\n",
            "Average clustering coefficient for Mentions Graph without 'xoxoday' (Directed): 0.035981912796703895\n",
            "Average clustering coefficient for Replies Graph without 'xoxoday' (Directed): 0.0\n"
          ]
        }
      ],
      "source": [
        "# Clustering coefficient for Full Graph (Mentions + Replies) without 'xoxoday' (Directed)\n",
        "clustering_coef_no_xoxoday_full = nx.average_clustering(G_no_xoxoday, weight=None)\n",
        "print(f\"Average clustering coefficient for Full Graph without 'xoxoday' (Directed): {clustering_coef_no_xoxoday_full}\")\n",
        "\n",
        "# Clustering coefficient for Mentions Graph without 'xoxoday' (Directed)\n",
        "clustering_coef_no_xoxoday_mentions = nx.average_clustering(G_mentions_no_xoxoday, weight=None)\n",
        "print(f\"Average clustering coefficient for Mentions Graph without 'xoxoday' (Directed): {clustering_coef_no_xoxoday_mentions}\")\n",
        "\n",
        "# Clustering coefficient for Replies Graph without 'xoxoday' (Directed)\n",
        "clustering_coef_no_xoxoday_replies = nx.average_clustering(G_replies_no_xoxoday, weight=None)\n",
        "print(f\"Average clustering coefficient for Replies Graph without 'xoxoday' (Directed): {clustering_coef_no_xoxoday_replies}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4APknjswNXT1"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OmkSMGQrNXeD",
        "outputId": "168b5d52-c22a-4a26-8ffd-e07f63fb8855"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Degree assortativity for Full Graph (with 'xoxoday'): -0.388050420374134\n",
            "Degree assortativity for Full Graph (without 'xoxoday'): -0.4329488018878232\n",
            "Degree assortativity for Mentions Graph (with 'xoxoday'): -0.38744128173397335\n",
            "Degree assortativity for Mentions Graph (without 'xoxoday'): -0.4332558356614266\n",
            "Degree assortativity for Replies Graph (with 'xoxoday'): -0.6693109942772173\n",
            "Degree assortativity for Replies Graph (without 'xoxoday'): nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/networkx/algorithms/assortativity/correlation.py:302: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return float((xy * (M - ab)).sum() / np.sqrt(vara * varb))\n"
          ]
        }
      ],
      "source": [
        "# Degree assortativity for the Full Graph (with and without 'xoxoday')\n",
        "assortativity_full = nx.degree_assortativity_coefficient(G)\n",
        "assortativity_full_no_xoxoday = nx.degree_assortativity_coefficient(G_no_xoxoday)\n",
        "\n",
        "# Degree assortativity for the Mentions Graph (with and without 'xoxoday')\n",
        "assortativity_mentions = nx.degree_assortativity_coefficient(G_mentions)\n",
        "assortativity_mentions_no_xoxoday = nx.degree_assortativity_coefficient(G_mentions_no_xoxoday)\n",
        "\n",
        "# Degree assortativity for the Replies Graph (with and without 'xoxoday')\n",
        "assortativity_replies = nx.degree_assortativity_coefficient(G_replies)\n",
        "assortativity_replies_no_xoxoday = nx.degree_assortativity_coefficient(G_replies_no_xoxoday)\n",
        "\n",
        "# Print results\n",
        "print(f\"Degree assortativity for Full Graph (with 'xoxoday'): {assortativity_full}\")\n",
        "print(f\"Degree assortativity for Full Graph (without 'xoxoday'): {assortativity_full_no_xoxoday}\")\n",
        "\n",
        "print(f\"Degree assortativity for Mentions Graph (with 'xoxoday'): {assortativity_mentions}\")\n",
        "print(f\"Degree assortativity for Mentions Graph (without 'xoxoday'): {assortativity_mentions_no_xoxoday}\")\n",
        "\n",
        "print(f\"Degree assortativity for Replies Graph (with 'xoxoday'): {assortativity_replies}\")\n",
        "print(f\"Degree assortativity for Replies Graph (without 'xoxoday'): {assortativity_replies_no_xoxoday}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi8BIn5tuiIt"
      },
      "source": [
        "# Detecting Communities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mW3dvumuPxsc",
        "outputId": "69a298e2-a5ec-4ead-82f2-b0c666895cb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Detecting communities in Full Graph (with 'xoxoday')...\n",
            "  Number of communities detected: 11\n",
            "  Size of largest community: 1860\n",
            "\n",
            "Detecting communities in Full Graph (without 'xoxoday')...\n",
            "  Number of communities detected: 141\n",
            "  Size of largest community: 1860\n",
            "\n",
            "Detecting communities in Mentions Graph (with 'xoxoday')...\n",
            "  Number of communities detected: 12\n",
            "  Size of largest community: 1860\n",
            "\n",
            "Detecting communities in Mentions Graph (without 'xoxoday')...\n",
            "  Number of communities detected: 142\n",
            "  Size of largest community: 1860\n",
            "\n",
            "Detecting communities in Replies Graph (with 'xoxoday')...\n",
            "  Number of communities detected: 8\n",
            "  Size of largest community: 76\n",
            "\n",
            "Detecting communities in Replies Graph (without 'xoxoday')...\n",
            "  Number of communities detected: 82\n",
            "  Size of largest community: 3\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import community.community_louvain as community_louvain  # âœ… correct import\n",
        "\n",
        "\n",
        "def detect_communities(graph, label):\n",
        "    print(f\"\\nDetecting communities in {label}...\")\n",
        "\n",
        "    # Louvain requires an undirected graph; this is still necessary\n",
        "    undirected_graph = graph.to_undirected()\n",
        "    partition = community_louvain.best_partition(undirected_graph)\n",
        "\n",
        "    # Count community sizes\n",
        "    community_sizes = Counter(partition.values())\n",
        "    print(f\"  Number of communities detected: {len(community_sizes)}\")\n",
        "    print(f\"  Size of largest community: {max(community_sizes.values())}\")\n",
        "\n",
        "    return partition, community_sizes\n",
        "\n",
        "# Run community detection on all six graphs\n",
        "partition_full, _ = detect_communities(G, \"Full Graph (with 'xoxoday')\")\n",
        "partition_full_no_xoxo, _ = detect_communities(G_no_xoxoday, \"Full Graph (without 'xoxoday')\")\n",
        "\n",
        "partition_mentions, _ = detect_communities(G_mentions, \"Mentions Graph (with 'xoxoday')\")\n",
        "partition_mentions_no_xoxo, _ = detect_communities(G_mentions_no_xoxoday, \"Mentions Graph (without 'xoxoday')\")\n",
        "\n",
        "partition_replies, _ = detect_communities(G_replies, \"Replies Graph (with 'xoxoday')\")\n",
        "partition_replies_no_xoxo, _ = detect_communities(G_replies_no_xoxoday, \"Replies Graph (without 'xoxoday')\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5panF1vtqOFM"
      },
      "source": [
        "Graph Type\tWith 'xoxoday'\tWithout 'xoxoday'\tLargest Community Size\tFragmentation\n",
        "Full (Mentions+Replies)\t11 communities\t143 communities\t1860\tâ†‘ Higher without xoxo\n",
        "Mentions\t13 communities\t140 communities\t1860\tâ†‘ Higher without xoxo\n",
        "Replies\t8 communities\t82 communities\t76 â†’ 3\tHuge â†‘ without xoxo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqH3SP6WuZrI"
      },
      "source": [
        "# Hashtag Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_oxCR79uuD3l",
        "outputId": "592c000f-7342-4ce5-e2f0-db97f960a8f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Analyzing hashtags...\n",
            "Top 10 hashtags:\n",
            "contest live rt: 186\n",
            "contest: 151\n",
            "live participate rt win contestalert contest: 103\n",
            "contest rt win contestalert: 75\n",
            "contestalert: 65\n",
            "participate contest rt: 57\n",
            "live contest rt: 46\n",
            "contestalert contest: 43\n",
            "contest contestalert: 29\n",
            "contest live rt contestalert: 28\n"
          ]
        }
      ],
      "source": [
        "if 'Hashtags in Tweet' in tweets.columns:\n",
        "    print(\"\\nAnalyzing hashtags...\")\n",
        "\n",
        "    # Extract all hashtags\n",
        "    all_hashtags = []\n",
        "    for hashtags in tweets['Hashtags in Tweet'].dropna():\n",
        "        if isinstance(hashtags, str):\n",
        "            # Assuming hashtags are stored as a comma-separated string\n",
        "            tags = [tag.strip() for tag in hashtags.split(',')]\n",
        "            all_hashtags.extend(tags)\n",
        "\n",
        "    # Count hashtag frequency\n",
        "    hashtag_counts = Counter(all_hashtags)\n",
        "\n",
        "    print(\"Top 10 hashtags:\")\n",
        "    for hashtag, count in hashtag_counts.most_common(10):\n",
        "        print(f\"{hashtag}: {count}\")\n",
        "\n",
        "    # Create hashtag co-occurrence network\n",
        "    hashtag_network = nx.Graph()\n",
        "\n",
        "    for hashtags in tweets['Hashtags in Tweet'].dropna():\n",
        "        if isinstance(hashtags, str):\n",
        "            tags = [tag.strip() for tag in hashtags.split(',')]\n",
        "            # Add edges between all pairs of hashtags in the same tweet\n",
        "            for i, tag1 in enumerate(tags):\n",
        "                for tag2 in tags[i+1:]:\n",
        "                    if hashtag_network.has_edge(tag1, tag2):\n",
        "                        hashtag_network[tag1][tag2]['weight'] += 1\n",
        "                    else:\n",
        "                        hashtag_network.add_edge(tag1, tag2, weight=1)\n",
        "\n",
        "    # Calculate centrality measures for hashtags\n",
        "    if hashtag_network.number_of_nodes() > 0:\n",
        "        hashtag_degree = nx.degree_centrality(hashtag_network)\n",
        "        hashtag_betweenness = nx.betweenness_centrality(hashtag_network)\n",
        "\n",
        "        # Create dataframe of hashtag metrics\n",
        "        hashtag_df = pd.DataFrame({\n",
        "            'hashtag': list(hashtag_network.nodes()),\n",
        "            'frequency': [hashtag_counts.get(tag, 0) for tag in hashtag_network.nodes()],\n",
        "            'degree': [hashtag_degree.get(tag, 0) for tag in hashtag_network.nodes()],\n",
        "            'betweenness': [hashtag_betweenness.get(tag, 0) for tag in hashtag_network.nodes()]\n",
        "        })\n",
        "\n",
        "        # Sort by frequency\n",
        "        hashtag_df = hashtag_df.sort_values('frequency', ascending=False)\n",
        "\n",
        "        print(\"\\nTop hashtags by network centrality:\")\n",
        "        print(hashtag_df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lpPD3uJGwHpm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJMtvB2du59H"
      },
      "source": [
        "# Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WssCKMtu6Gd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "# Create output directory for visualizations\n",
        "os.makedirs('network_visualizations', exist_ok=True)\n",
        "\n",
        "# Convert to undirected graph for community detection\n",
        "G_undirected = G.to_undirected()\n",
        "\n",
        "# Perform community detection on the undirected graph\n",
        "partition = community_louvain.best_partition(G_undirected)\n",
        "\n",
        "# Calculate PageRank for the graph (this will give you a dictionary of node -> PageRank)\n",
        "pagerank = nx.pagerank(G)\n",
        "\n",
        "# 1. Network visualization with community colors\n",
        "def plot_network(G, partition=None, filename='network.png', title='Network Visualization',\n",
        "                 node_size_attr=None, layout=nx.spring_layout):\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    pos = layout(G)\n",
        "\n",
        "    # Node sizes based on centrality if provided\n",
        "    if node_size_attr:\n",
        "        node_size = [50 + 1000 * node_size_attr.get(node, 0) for node in G.nodes()]\n",
        "    else:\n",
        "        node_size = 50\n",
        "\n",
        "    # Node colors based on community if provided\n",
        "    if partition:\n",
        "        colors = [partition.get(node, 0) for node in G.nodes()]\n",
        "        nx.draw_networkx_nodes(G, pos, node_size=node_size,\n",
        "                              node_color=colors, cmap=plt.cm.rainbow, alpha=0.8)\n",
        "    else:\n",
        "        nx.draw_networkx_nodes(G, pos, node_size=node_size, alpha=0.8)\n",
        "\n",
        "    nx.draw_networkx_edges(G, pos, alpha=0.2, arrows=True)\n",
        "\n",
        "    # Only label highest degree nodes for readability\n",
        "    if node_size_attr:\n",
        "        top_nodes = sorted(node_size_attr.items(), key=lambda x: x[1], reverse=True)[:20]\n",
        "        labels = {node: node for node, _ in top_nodes if node in G}\n",
        "        nx.draw_networkx_labels(G, pos, labels=labels, font_size=8)\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'network_visualizations/{filename}', dpi=300)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "\n",
        "plot_network(G, partition=partition, filename='network_communities.png',\n",
        "             title='Twitter Network with Communities', node_size_attr=pagerank)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3CHfEfa1_po"
      },
      "outputs": [],
      "source": [
        "pip install nltk scikit-learn wordcloud matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1CEH2Ts8AwC"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOXbWjHo8jTK"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from wordcloud import WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfA-tztrXjd6"
      },
      "outputs": [],
      "source": [
        "!pip install \"numpy>=2.0.0,<3.0.0\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkMqXQJAYpyt"
      },
      "outputs": [],
      "source": [
        "!pip install pandas matplotlib seaborn nltk scikit-learn wordcloud\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KjdWlCpfly4"
      },
      "source": [
        "## Libraries for Text Mining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VddYx7LYfl9D"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "# NLP Libraries\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrNcl2x_e7gQ"
      },
      "source": [
        "## Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VU0xMR0leimZ"
      },
      "outputs": [],
      "source": [
        "# Define your custom STOPWORDS properly as a set\n",
        "STOPWORDS = set(\"\"\"i me my myself we our ours ourselves you your yours yourself yourselves\n",
        "                he him his himself she her hers herself fotokiran blessedkamal calljain girijakriz\n",
        "                it its itself they them their theirs themselves what which who whom this that these\n",
        "                those am is are was were romaguptasinha contesttable like wants esrihari everyon be\n",
        "                been being have has had having do does did doing a an the and but if or because as\n",
        "                until while of at by corallista mehandisuresh vineetsonkar sayyedjenifer bhansalidigna\n",
        "                for with about against thexoxoday between into through during before after above below\n",
        "                to from up down in out pinkydholakia babubeg want microlight xoxoday acharyaempire on\n",
        "                off over under again further then once here there when where why how all any both each\n",
        "                few more most other iheartcontest deepaadhan plumparadise korakagaj particip some such\n",
        "                no nor not contestalert only own same so than too very s t can will just don should now\n",
        "                hi check guys dhillonshalini nsverma contestkiduniyaimport re import string from nltk contestadventur contestmantra contestmela contesthub\n",
        "                thefreejinn shraddhabari snehalataj sureshnakoda go see indiancontests would aadiivaasii\"\"\".split())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rorInHKie1Y-"
      },
      "source": [
        "##Pre-processing text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h1FzdjSzejL-"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"Preprocess text with lemmatization and custom stopwords, printing @words and their original tweets.\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n",
        "\n",
        "    # Split text into tokens\n",
        "    tokens = text.split()\n",
        "\n",
        "    # Print usernames (starting with @) and the original tweet if any are found\n",
        "    at_words = [word for word in tokens if word.startswith('@')]\n",
        "    if at_words:\n",
        "        print(\"Tweet with @words:\", text)\n",
        "        print(\"Removed @words:\", at_words)\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "    # Filter out stopwords, non-alpha tokens, and words starting with @\n",
        "    tokens = [word for word in tokens if word.isalpha() and word not in STOPWORDS and not word.startswith('@')]\n",
        "\n",
        "    # Lemmatize each token (defaulting to noun)\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return \" \".join(tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TiSwXJCezNS"
      },
      "source": [
        "## TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbkVSkNeex8v"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 1. TF-IDF Analysis\n",
        "def perform_tfidf_analysis(documents):\n",
        "    \"\"\"Perform TF-IDF analysis on preprocessed documents\"\"\"\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        preprocessor=lambda x: x,  # Text is already preprocessed\n",
        "        tokenizer=str.split,       # Simple whitespace split\n",
        "        stop_words=None            # No need for built-in stopwords since we already filtered\n",
        "    )\n",
        "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "    tfidf_array = tfidf_matrix.toarray()\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "    # Sum TF-IDF scores across all documents\n",
        "    total_tfidf = np.sum(tfidf_array, axis=0)\n",
        "\n",
        "    # Pair words with scores and sort\n",
        "    word_scores = list(zip(feature_names, total_tfidf))\n",
        "    word_scores_sorted = sorted(word_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return tfidf_matrix, feature_names, word_scores_sorted, vectorizer\n",
        "\n",
        "# Perform TF-IDF analysis\n",
        "tfidf_matrix, feature_names, word_scores_sorted, vectorizer = perform_tfidf_analysis(documents_cleaned)\n",
        "\n",
        "# Display top TF-IDF scores\n",
        "print(\"Top TF-IDF scores across all tweets:\")\n",
        "for word, score in word_scores_sorted[:20]:\n",
        "    print(f\"{word}: {score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAF_UEtnfvbs"
      },
      "source": [
        "## Word Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mhk6DwJWfUQV"
      },
      "outputs": [],
      "source": [
        "def generate_wordcloud_from_tfidf(word_scores):\n",
        "    \"\"\"Generate word cloud from TF-IDF scores\"\"\"\n",
        "    # Create a dictionary of words and their scores\n",
        "    tfidf_dict = {word: score for word, score in word_scores}\n",
        "\n",
        "    # Generate word cloud from TF-IDF scores\n",
        "    wordcloud = WordCloud(\n",
        "        width=800,\n",
        "        height=400,\n",
        "        background_color='white'\n",
        "    ).generate_from_frequencies(tfidf_dict)\n",
        "\n",
        "    # Display the Word Cloud\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Word Cloud Based on TF-IDF Scores\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return wordcloud\n",
        "\n",
        "# Generate word cloud from TF-IDF results\n",
        "wordcloud = generate_wordcloud_from_tfidf(word_scores_sorted)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8EzyKA3f1S1"
      },
      "source": [
        "## N-Gram Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flBRxTR1f1cr"
      },
      "outputs": [],
      "source": [
        "def extract_ngrams(texts, n=2):\n",
        "    \"\"\"Extract n-grams from a list of preprocessed texts\"\"\"\n",
        "    all_ngrams = []\n",
        "    for text in texts:\n",
        "        tokens = text.split()\n",
        "        if len(tokens) >= n:\n",
        "            all_ngrams.extend(list(ngrams(tokens, n)))\n",
        "    return Counter(all_ngrams)\n",
        "\n",
        "# Extract bigrams and trigrams\n",
        "bigram_counts = extract_ngrams(documents_cleaned, 2)\n",
        "trigram_counts = extract_ngrams(documents_cleaned, 3)\n",
        "\n",
        "print(\"\\nTop 10 bigrams:\")\n",
        "for gram, count in bigram_counts.most_common(10):\n",
        "    print(f\"{' '.join(gram)}: {count}\")\n",
        "\n",
        "print(\"\\nTop 10 trigrams:\")\n",
        "for gram, count in trigram_counts.most_common(10):\n",
        "    print(f\"{' '.join(gram)}: {count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJnentbKf6OP"
      },
      "source": [
        "##  Topic Modeling with LDA (sklearn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3xLY4Ix-f6aX",
        "outputId": "77b410d5-cc2d-4da0-a72a-18e382a426bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Identified 15 topics:\n",
            "Topic 1: join, chulbullychidya, buddiez, modipreksha, ghunjain, contestsinindia, gpkm, sunitakatyal, contestsource, iampratikjadhav\n",
            "Topic 2: join, rt, tofarzeen, tagging, shivzi, hashloverz, garbadandiya, hiddenkeys, smojawala, hoorparee\n",
            "Topic 3: one, bygpass, pas, getfit, olacabs, nearbuy, flexibility, allget, complete, snapdeal\n",
            "Topic 4: uberindia, join, offer, flight, love, hetalrawat, prateekuapdhya, nishajg, imbevda, atulkrin\n",
            "Topic 5: market, offbeat, firm, plan, enter, marketing, bengalurubased, prreleasewatch, tajmahalpalace, wasidkh\n",
            "Topic 6: join, nitincul, hellolalit, amazing, acharinimboo, chidiyagiri, mrrahuljoshi, iamkoolazzu, khannaronit, mgossipqueen\n",
            "Topic 7: rt, contest, u, participate, coming, follow, shoutout, live, give, photocontests\n",
            "Topic 8: rt, contest, friend, live, win, participate, follow, tag, tagging, u\n",
            "Topic 9: join, r, rtadepally, irinrinki, sensiblemona, djshivamanuja, karrivinodkumar, itzpman, nosaiyoha, teehoo\n",
            "Topic 10: join, vhetal, binnykukreja, akiinaik, shounakbafna, aboutcontests, contestfreaks, thing, wow, mistybasu\n",
            "Topic 11: join, wish, thanks, feeling, childhood, express, varmaila, johnterencea, sarathkevinjoy, contestrun\n",
            "Topic 12: reachskk, malavikamallya, vivekagw, kushalagrl, abhimanyusays, kailasim, kamnaagrawal, awesome, thise, chocos\n",
            "Topic 13: join, experience, contestkiduniya, fun, dine, new, always, wid, looking, ti\n",
            "Topic 14: join, climate, satyasroy, ankibn, siljapillai, brother, jasbny, beemji, itisprashanth, agnelsujinx\n",
            "Topic 15: rt, win, ride, dinner, friend, taj, contest, audi, live, tag\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def perform_sklearn_lda(documents, num_topics=15, num_words=10):\n",
        "    \"\"\"Perform LDA topic modeling using sklearn\"\"\"\n",
        "    # Preprocess documents\n",
        "    documents_cleaned = [preprocess_text(doc) for doc in documents]\n",
        "\n",
        "    # Create CountVectorizer for LDA\n",
        "    count_vectorizer = CountVectorizer(\n",
        "        preprocessor=lambda x: x,  # Text is already preprocessed\n",
        "        tokenizer=str.split        # Simple whitespace split\n",
        "    )\n",
        "    count_matrix = count_vectorizer.fit_transform(documents_cleaned)\n",
        "    feature_names = count_vectorizer.get_feature_names_out()\n",
        "\n",
        "    # Train LDA model\n",
        "    lda = LatentDirichletAllocation(\n",
        "        n_components=num_topics,\n",
        "        random_state=42,\n",
        "        max_iter=10,\n",
        "        learning_method='online'\n",
        "    )\n",
        "    lda.fit(count_matrix)\n",
        "\n",
        "    # Extract topics\n",
        "    topics = []\n",
        "    for topic_idx, topic in enumerate(lda.components_):\n",
        "        # Sort words by importance in topic\n",
        "        top_features_idx = topic.argsort()[:-num_words-1:-1]\n",
        "        top_features = [feature_names[i] for i in top_features_idx]\n",
        "        topics.append(top_features)\n",
        "\n",
        "    # Assign topics to documents\n",
        "    doc_topics = lda.transform(count_matrix)\n",
        "    main_topics = doc_topics.argmax(axis=1)\n",
        "\n",
        "    return lda, topics, main_topics, count_vectorizer\n",
        "\n",
        "# Perform LDA topic modeling\n",
        "num_topics = 15  # Adjust based on your dataset size\n",
        "lda_model, topics, doc_topics, count_vectorizer = perform_sklearn_lda(documents_cleaned, num_topics)\n",
        "\n",
        "# Print topics\n",
        "print(f\"\\nIdentified {num_topics} topics:\")\n",
        "for i, topic_words in enumerate(topics):\n",
        "    print(f\"Topic {i+1}: {', '.join(topic_words)}\")\n",
        "\n",
        "# Add topics back to original dataframe (if needed)\n",
        "tweets['topic'] = pd.Series(doc_topics, index=tweets.index[:len(doc_topics)])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvaXo1EggD4a"
      },
      "source": [
        "## Basic Text Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ji7PBWlggEDX"
      },
      "outputs": [],
      "source": [
        "def compute_text_stats(texts):\n",
        "    \"\"\"Compute basic text statistics\"\"\"\n",
        "    stats = {\n",
        "        'total_documents': len(texts),\n",
        "        'total_words': sum(len(text.split()) for text in texts),\n",
        "        'unique_words': len(set(word for text in texts for word in text.split())),\n",
        "    }\n",
        "    return stats\n",
        "\n",
        "# Compute basic text statistics\n",
        "text_stats = compute_text_stats(documents_cleaned)\n",
        "print(\"\\nBasic Text Statistics:\")\n",
        "for stat, value in text_stats.items():\n",
        "    print(f\"{stat}: {value:.2f}\" if isinstance(value, float) else f\"{stat}: {value}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "FEIBSkrtIZNj",
        "Ad5acGk9PtE0"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
